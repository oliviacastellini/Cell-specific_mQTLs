---
title: "Replication of mQTLs associations across contexts"
author: Olivia Castellini-Pérez
date: October 30, 2023
abstract: ""
output:  
  bookdown::pdf_book:
  keep_tex: true
fig_caption: yes
toc: true
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Methods
## Samples

```{r, include=FALSE}
library(readxl)
table1<-read_excel("/user/home/uy23281/scratch/rmd.results/Table1_Samples.xlsx",col_names = T)
table1<-as.data.frame(table1)
```

```{r table1, echo=FALSE}
knitr::kable(table1,format="latex",digits=400,booktabs = T,align="c")
```
 
## Models 

(1) n=all, data=bulk, model=interaction, cell-type=x4(salas), region=cis, cell-count=predicted
(2) n=all, data=bulk, model=interaction, cell-type=x4(salas), region=cis, cell-count=observed
(3) n=all, data=cell-specific, model=main, cell-type=x4(sorted), region=cis
(4) n=overlap(~60), data=cell-specific, model=main, cell-type=x4(sorted), region=cis
(5) n=overlap(~60), data=bulk, model=interaction, cell-type=x4(the same as sorted), region=cis

# Replication
  
  1. Are the GoDMC SNP-CpG pairs replicating in bulk+int?
  2. Are the GoDMC SNP-CpG pairs replicating in cell-specific? 
  3. Discovery in bulk+int replicating in cell-specific?  
  4. Discovery in cell-specific replicating in bulk?
  5. Any pvalues from mod1 or mod2 with FDR < 0.05?
  
True positives:
1. Get cell-specific associations in model 3 - use FDR < 0.05 for heterogeneity test
2. Look to see if they replicate in predicted cell counts (model 1)
False positives:
1. Get cell-specific associations in predicted cell counts (model 1)
2. Replication in model 3

## GoDMC SNP-CpG pairs replication
  
```{r, include=FALSE}
library(dplyr)
library(data.table)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(epiR)
library(stats)
library(car)
library(forestplot)
library(gridExtra)
library(cowplot)
library(png)
```

```{r, include=FALSE}
standardise <- function(d, ea="ea", oa="oa", beta="beta", chr="chr", pos="pos") {
  toflip <- d[[ea]] > d[[oa]]
  d[[beta]][toflip] <- d[[beta]][toflip] * -1
  temp <- d[[oa]][toflip]
  d[[oa]][toflip] <- d[[ea]][toflip]
  d[[ea]][toflip] <- temp
  d[["snpid"]] <- paste0(d[[chr]], ":", d[[pos]], "_", toupper(d[[ea]]), "_", toupper(d[[oa]]))
  d
}

repl_obs_exp <- function(b_disc, b_rep, se_disc, se_rep, alpha) {
  p_sign <- pnorm(-abs(b_disc) / se_disc) * pnorm(-abs(b_disc) / se_rep) + ((1 - pnorm(-abs(b_disc) / se_disc)) * (1 - pnorm(-abs(b_disc) / se_rep)))
  p_sig <- pnorm(-abs(b_disc) / se_rep + qnorm(alpha / 2)) + (1 - pnorm(-abs(b_disc) / se_rep - qnorm(alpha / 2)))
  p_rep <- pnorm(abs(b_rep)/se_rep, lower.tail=FALSE)
  res <- tibble::tibble(
    nsnp=length(b_disc),
    metric=c("Sign", "Sign", "P-value", "P-value"),
    datum=c("Expected", "Observed", "Expected", "Observed"),
    value=c(sum(p_sign, na.rm=TRUE), sum(sign(b_disc) == sign(b_rep)), sum(p_sig, na.rm=TRUE), sum(p_rep < alpha, na.rm=TRUE))
  )
  return(list(res=res, variants=dplyr::tibble(sig=p_sig, sign=p_sign)))
}

# Read in clumped
load("/user/home/uy23281/scratch/16_clumped.rdata")
#load("/home/uy23281/data/16_clumped.rdata")
# Organise data
clumped <- ungroup(clumped)
clumped$snpchr <- gsub("chr", "", clumped$snpchr)
clumped2 <- standardise(clumped, "Allele2", "Allele1", "Effect", "snpchr", "snppos")

```

# Results
## Relationship between GoDMC and cell-sorted model effects
```{r, include=FALSE}
# Reading sd file
sds<-read.table("/user/home/uy23281/scratch/rmd.results/model4/neu/sd.methy.txt",header=T,sep="\t")

# Reading results 
load("/user/home/uy23281/scratch/rmd.results/model4/model4_extracted.RData")
cell <- left_join(m4_sig, sds, by = c("gene" = "cpg"))
    
# Subset based on the clumped$cpg values
cell <- subset(cell, gene %in% clumped$cpg)
    
# Separate SNP column into chr and pos
cell <- cell  %>% tidyr::separate(SNP, sep = ":", into = c("chr", "pos"))
    
# Separate pos column into pos, a1, and a2
cell <- cell %>% tidyr::separate(pos, sep = "_", into = c("pos", "a1", "a2"))
    
# Standardize cell data
cell2 <- standardise(cell, "a1", "a2", "beta", "chr", "pos")
    
# Merge with clumped2 data
m <- inner_join(clumped2, cell2, by = c("snpid", "cpg" = "gene"))
    
# Calculate standard error
m$se <- m$beta / m$`t-stat`
m$se_std<-m$se/m$sd
m$beta_std<-m$beta/m$sd

# 1 Relationship between the effects
# Create separate data frames for each analysis
results_lm <- data.frame()
results_prop_table <- data.frame()
results_repl_rate <- data.frame()

# Get unique cell types from your data
unique_celltypes <- unique(m$celltype)

for (celltype in 1:length(unique_celltypes)) {
  # Subset the data based on the celltype condition
 subset_data <- m[m$celltype == unique_celltypes[celltype], ]
  
  # 1. Linear regression
  full <- lm(beta_std ~ Effect, data = subset_data)
  fitted <- summary(full)$coefficients
  result_row_lm <- data.frame(CellType = unique_celltypes[celltype], Beta = fitted[2, 1], SE = fitted[2, 2], PValue = fitted[2, 4])
  results_lm <- rbind(results_lm, result_row_lm)
  
  # 2. Overall replication rate
  prop_table <- table(subset_data$`p-value` < 0.05) %>% prop.table()
  prop_table_row <- data.frame(CellType = unique_celltypes[celltype], PropTable = prop_table)
  results_prop_table <- rbind(results_prop_table, prop_table_row)
  
  # 3. Replication rate
  repl <- repl_obs_exp(subset_data$Effect, subset_data$beta_std, subset_data$StdErr, subset_data$se_std, 5e-6)
  repl_df <- as.data.frame(repl$res)
  repl_row <- data.frame(CellType = unique_celltypes[celltype], Model = "Replication Rate", Repl = repl_df)
  results_repl_rate <- rbind(results_repl_rate, repl_row)
}

##  r function for formatting p-values
# 
# format.pvalue <- function(x) {
#   formatted.x <- ifelse(x > 0.01,
#                         formatC(x, digits = 2, format = "f"),
#                         formatC(x, digits = 0))
#   return(formatted.x)
# }
# results_df[, PValue := format.pvalue(PValue)]
# results_df[, Beta := formatC(Beta, digits = 4, format = "f")]
# results_df[, SE := formatC(SE, digits = 4, format = "f")]

#Save the plot 
# grid_plots <- grid.arrange(grobs = plots_list, ncol = 2, nrow = 2)
# ggsave(filename = "/user/home/uy23281/scratch/rmd.results/model4/Effect_plot.png", plot = grid_plots)
```

### Linear regression between GoDMC and m4 effects
```{r results_m4_df, echo=FALSE}
print(results_lm)
```

### Overall replication rate
```{r prop_table_m4_df, echo=FALSE}
print(results_prop_table)
```

### Replication rate (observed vs expected)
```{r repl_m4_df, echo=FALSE}
print(results_repl_rate)
```

### Plots
```{r plot2, out.width="80%", fig.align="center",fig.cap=c("GoDMC effect versus model 4 effect"), echo=FALSE}
knitr::include_graphics("/user/home/uy23281/scratch/rmd.results/model4/Effect_plot.png")

```

## Heterogeneity test for each cell in model 3
### Cell-specific associations for netrophils model 3
```{r include=FALSE}
# For neutrophils
load("/user/home/uy23281/scratch/rmd.results/model4/model4_extracted.RData")
m4_sig$se<- m4_sig$beta / m4_sig$`t-stat`

 # Read the function for the heterogeneity test
  fixed_effects_meta_analysis <- function(beta_vec, se_vec) {
    w <- 1 / se_vec^2
    beta <- sum(beta_vec * w, na.rm=T) / sum(w, na.rm=T)
    se <- sqrt(1 / sum(w, na.rm=T))
    pval <- pnorm(abs(beta / se), lower.tail = FALSE)
    Qj <- w * (beta-beta_vec)^2
    Q <- sum(Qj, na.rm=T)
    Qdf <- sum(!is.na(beta_vec))-1
    if(Qdf == 0) Q <- 0
    Qjpval <- pchisq(Qj, 1, lower.tail=FALSE)
    Qpval <- pchisq(Q, Qdf, lower.tail=FALSE)
    return(list(beta=beta, se=se, Q=Q, Qdf=Qdf, Qpval=Qpval, Qj=Qj, Qjpval=Qjpval))
  }

subset(m4_sig, SNP==SNP[1] & gene==gene[1])
temp <- subset(m4_sig, SNP==SNP[1] & gene==gene[1])
result<-fixed_effects_meta_analysis(temp$beta, temp$se)
m4_sig$code <- paste(m4_sig$SNP, m4_sig$gene)

out <- group_by(m4_sig, code) %>% do({temp <- .; 
r <- fixed_effects_meta_analysis(temp$beta, temp$se); 
tibble(beta=r$beta, se=r$se, Q=r$Q, Qdf=r$Qdf, Qpval=r$Qpval)})

#Forest plot by single SNP_cpg pairs  
plot_het <- function(m4_sig, cpgsnp) {
    subset(m4_sig, code == cpgsnp) %>%
    ggplot(., aes(x=beta, y = celltype)) +
    geom_point() +
    geom_errorbarh(aes(xmin=beta - 1.96*se, xmax=beta+1.96*se))+
    ggtitle(paste0("Model 4 (",cpgsnp,")"))
}
 
out$fdr <- p.adjust(out$Qpval, "fdr")
sighet <- subset(out, fdr < 0.05) %>% arrange(Qpval)

# Heterogeneity per celltype 
outj <- m4_sig %>% group_by(code) %>% do({
    x <- .
    r <- fixed_effects_meta_analysis(.$beta, .$se)
    tibble(code = .$code, celltype=.$celltype, qjpval = r$Qjpval)
})

outj_maxhet <- outj %>% group_by(code) %>%
    arrange(qjpval) %>%
    slice_head(n=1)

# Getting standard deviation for each cpg and celltype
celltypes <- c("neu", "mono", "tcell", "bcell")
results_list <- lapply(celltypes, function(x) {
file_path <- paste0("/user/home/uy23281/scratch/rmd.results/model4/sd.methy_",x,".txt")
data <- fread(file_path)
data$celltype <- x
return(data)
})

sd_df <- bind_rows(results_list)

# Extract unique cg ids and corresponding cell types
df_unique <- outj %>%
  mutate(cg_id = gsub(".* ", "", code)) %>%
  ungroup() %>%
  select(code,cg_id,celltype,qjpval)

# Merge with the standard deviation data frame
sd_df_unique <- inner_join(df_unique, sd_df, by = c("cg_id"="cpg","celltype"),multiple="all")

# Merging sd with sighet results
outj_maxhet<-outj_maxhet %>%
  mutate(cg_id=gsub(".* ", "", code)) 

maxhet_sd<-inner_join(outj_maxhet,sd_df,by=c("cg_id"="cpg","celltype"),multiple="all") %>%
  arrange(qjpval) %>%
  select(code,celltype,qjpval,cg_id,sd) %>%
  slice_head(n=1)

```

```{r,echo=FALSE}
out 
outj
outj_maxhet
table(p.adjust(out$Qpval, "fdr") < 0.05)
par(mfrow=c(2,2))
plot_het(m4_sig, sighet$code[1]) # Change the number to select another SNP-CpG pair
plot_het(m4_sig, sighet$code[2])
plot_het(m4_sig, sighet$code[3])
plot_het(m4_sig, sighet$code[4])
```
*Question*: Are the ones with the biggest heterogeneity the one with smallest or highest standard deviation ?

```{r,echo=FALSE}
sd_df_unique
maxhet_sd

```

## Correlations between models
### Model 4 hits with most heterogeneity vs model 1 
```{r, include=FALSE}
# Extract 100 SNP_cpg pairs with most heterogeneity in model 4
sighet_100<-sighet[1:100,]
snpscpg_het<-sighet_100$code

# Extract list SNP_CpG from model 1 results per cell type
results_list <- lapply(celltypes, function(x) {
  chunk_list <- lapply(1:7, function(y) {
    file_path <- paste0("/user/home/uy23281/scratch/rmd.results/model1/", x, "/res.cis.", y, ".gz")
    data <- fread(file_path)
    data_filtered <- data %>%
      filter(paste0(SNP," ",gene) %in% snpscpg_het)
    
    data_filtered$celltype <- x
    data_filtered
  })
  bind_rows(chunk_list)
})

m1_sighet <- bind_rows(results_list)

m1_sighet$code <- paste(m1_sighet$SNP, m1_sighet$gene)
m1_sighet$se<- m1_sighet$beta / m1_sighet$`t-stat`

# Function to create the plot
# plot_function <- function(df, model_name,cpg_snp) {
#   ggplot(df, aes(x = beta, y = celltype)) +
#     geom_point() +
#     geom_errorbarh(aes(xmin = beta - 1.96 * se, xmax = beta + 1.96 * se)) +
#     ggtitle(model_name) + xlab(paste0("beta (",cpg_snp,")"))
# }
# 
# num_examples <- 10
# 
# # Create a directory to save individual plots
# dir.create("/user/home/uy23281/scratch/rmd.results/individual_plots", showWarnings = FALSE)
# 
# # Loop through each example
# for (i in 1:num_examples) {
#   # Assuming cpg_snp is unique for each example
#   cpg_snp <- unique(m1_sighet$code)[i]
#   
#   # Subset data frames for the specific cpg_snp
#   subset_model1 <- subset(m1_sighet, code == cpg_snp)
#   subset_model2 <- subset(m4_sig, code == cpg_snp)
#   
#   # Create plots for each model
#   plot_model1 <- plot_function(subset_model1, "Model 1",cpg_snp)
#   plot_model2 <- plot_function(subset_model2, "Model 2",cpg_snp)
#   
#   # Save each plot with a unique filename
#   ggsave(paste0("/user/home/uy23281/scratch/rmd.results/individual_plots/plot_", i, "_model1.png"), plot_model1)
#   ggsave(paste0("/user/home/uy23281/scratch/rmd.results/individual_plots/plot_", i, "_model2.png"), plot_model2)
# }
# 
# # Function to read and arrange images for a specific plot
combine_plot_images <- function(plot_number) {
  # List of PNG file names for model1 and model2
  model1_files <- sprintf("/user/home/uy23281/scratch/rmd.results/individual_plots/plot_%d_model1.png", plot_number)
  model2_files <- sprintf("/user/home/uy23281/scratch/rmd.results/individual_plots/plot_%d_model2.png", plot_number)

  # Read images for model1 and model2
  model1_image <- png::readPNG(model1_files)
  model2_image <- png::readPNG(model2_files)

  # Combine images for model1 and model2
  combined_row <- grid.arrange(
    grid::rasterGrob(model1_image),
    grid::rasterGrob(model2_image),
    ncol = 2
  )

  # Return the combined row
  return(combined_row)
}

# pdf("/user/home/uy23281/scratch/rmd.results/combined_image.pdf",width = 14, height = 8)
# Combine images for each plot
for (plot_number in 1:10) {
  # Generate the combined plot
  combined_plot <- combine_plot_images(plot_number)
  
  # Print the combined plot to the PDF
  grid.draw(combined_plot)
}

# Close the PDF device
# dev.off()

```

### Model1 and model2
```{r, include=FALSE}
load("/user/home/uy23281/scratch/rmd.results/model1/model1_extracted.RData")
load("/user/home/uy23281/scratch/rmd.results/model2/model2_extracted.RData")
m2_sig$SNP_cpg<-paste0(m2_sig$SNP,"_",m2_sig$gene)
m1_sig$SNP_cpg<-paste0(m1_sig$SNP,"_",m1_sig$gene)

# Create a list of your data frames (assuming you have already loaded them)
df_list <- list(m2_sig, m1_sig)  # Replace df1 and df2 with your actual data frames

# List of cell types
cell_types <- c("neu", "mono", "tcell", "bcell")

# Create an empty list to store the correlation results
correlation_results <- list()

# Loop through all combinations of cell types across models
for (n in 1:length(cell_types)) {
  for (i in 1:length(cell_types)) {
    # Subset the data frames for the current cell types in each model
    cell_type_data_1 <- lapply(df_list, function(df) df[df$celltype == cell_types[n], ])
    cell_type_data_2 <- lapply(df_list, function(df) df[df$celltype == cell_types[i], ])
    
    # Find the common SNP_cpg pairs for the current cell types in each model
    common_snp_cpg <- intersect(cell_type_data_1[[1]]$SNP_cpg, cell_type_data_2[[2]]$SNP_cpg)
    
    # Filter data frames to only include common SNP_cpg pairs
    df1_filtered <- cell_type_data_1[[1]][cell_type_data_1[[1]]$SNP_cpg %in% common_snp_cpg, ]
    df2_filtered <- cell_type_data_2[[2]][cell_type_data_2[[2]]$SNP_cpg %in% common_snp_cpg, ]
    
    # Extract the beta values for each data frame
    beta_values_1 <- df1_filtered$beta
    beta_values_2 <- df2_filtered$beta
    
    # Calculate the pairwise correlation between beta values
    correlation_result <- cor(beta_values_1, beta_values_2, use = "complete.obs")
    
    # Store the correlation result in the list with a meaningful label
    correlation_results[[paste(cell_types[n], "vs", cell_types[i])]] <- correlation_result
  }
}

```

```{r correlation_results, echo=FALSE}
# Print the correlation results
for (correlation_label in names(correlation_results)) {
  cat("Cell Types:", correlation_label, "\n")
  cat("Correlation between models:", correlation_results[[correlation_label]], "\n")
}
```

## mashr 
```{r, include=FALSE}
## https://stephenslab.github.io/mashr/articles/intro_mash.html#step-2-set-up-the-covariance-matrices
library(mashr)
library(tidyr)
library(corrplot)
#Reading mashr prepared data significant top SNP_CpG pairs and 20,000 null SNP-Cpgs per cell type
load("/user/home/uy23281/scratch/rmd.results/mashr/mashr_m4.RData")
# Preparing data in right format
## Subsetting colmuns 
mashr_m4$snp_cpg<-paste0(mashr_m4$SNP,"_",mashr_m4$gene)
mashr_m4$se<- mashr_m4$beta / mashr_m4$`t-stat`
mashr_m4<-mashr_m4[order(mashr_m4$celltype),]

duplicates <- mashr_m4[duplicated(mashr_m4[c("snp_cpg", "celltype")]) & mashr_m4$celltype %in% unique(mashr_m4$celltype), ]
mashr_m4_unique <- mashr_m4 %>%
  distinct(snp_cpg, celltype, .keep_all = TRUE)

se_df<-subset(mashr_m4_unique,select=c("snp_cpg","se","celltype"))
beta_df<-subset(mashr_m4_unique,select=c("snp_cpg","beta","celltype"))

## Reshape the data frame
reshaped_beta <- spread(beta_df, key = celltype, value = beta)
reshaped_beta<-na.omit(reshaped_beta)
rownames(reshaped_beta)<-reshaped_beta[,1]
reshaped_beta<-reshaped_beta[,-1]

reshaped_se <- spread(se_df, key = celltype, value = se)
reshaped_se<-na.omit(reshaped_se)
rownames(reshaped_se)<-reshaped_se[,1]
reshaped_se<-reshaped_se[,-1]

reshaped_df <- list(
  Beta = reshaped_beta,
  SE = reshaped_se
)

## mashr needs matrix 
reshaped_df$Beta <- as.matrix(reshaped_df$Beta)
reshaped_df$SE <- as.matrix(reshaped_df$SE)
```

```{r,echo=TRUE}

# Step 1: Select strong signals. 
## Running a condition-by-condition (1by1) analysis on all the data
data = mash_set_data(reshaped_df$Beta, reshaped_df$SE)
m.1by1 = mash_1by1(data)
strong = get_significant_results(m.1by1,0.05)
## This sets up a vector strong containing the indices corresponding to 
## the significant rows of the tests results in data. 

# Step 2: Obtain initial data-driven covariance matrices  
## Here we use the function cov_pca to produce covariance matrices based on the 
## top 4 PCs of the strong signals. The result is a list of 6 covariance matrices: 
## one based on all 4 PCs, and the others each based on one PC
U.pca = cov_pca(data,4,subset=strong)
print(names(U.pca)) 

## Note that the number of conditions in the data is greater than or equal to 
## the number of principal components we are trying to compute. 

# Step 3: Apply Extreme Deconvolution
## Use these data-driven covariance matrices as initializations for the extreme
## deconvolution (ED) algorithm (using cov_ed), to get some refined data-driven 
## covariance matrix estimates
U.ed = cov_ed(data, U.pca, subset=strong)

# Step 4: Calculate canonical covariances
U.c = cov_canonical(data)  

# Step 5: Run mash with both data-driven covariances and canonical covariances
m.c    = mash(data, U.c)
m.ed   = mash(data, U.ed)
m   = mash(data, c(U.c,U.ed))
print(get_loglik(m.c),digits = 10)
print(get_loglik(m.ed),digits = 10)
print(get_loglik(m),digits = 10)

```
When running mashr it is recommended to fit with both data-driven and canonical covariances. This can be easily checked observing the log likelihood values. The biggest number would indicate the best fit so using both covariances methods. 
We now can use **get_significant_results()** to find the indices of effects that are “significant”, which here means they have **lfsr** less than t in at least one condition, where t is a threshold you specify (default 0.05). The output is ordered from most significant to least significant.

```{r, include=FALSE}
# png(file="/user/home/uy23281/scratch/rmd.results/barplot_mshr_m4.png")
# barplot(get_estimated_pi(m.c),las = 2)
# dev.off()
# 
# png(file="/user/home/uy23281/scratch/rmd.results/sigres_mshr_m4.png")
# mash_plot_meta(m.c,get_significant_results(m.c)[1])
# dev.off()

# If we fit the mash model without the posterior samples, we could use mash_compute_posterior_matrices to sample from the mash object.
# https://ftp.yz.yamagata-u.ac.jp/pub/math/cran/web/packages/mashr/vignettes/mash_sampling.html

#Correlation plot 
x = get_pairwise_sharing(m, factor=0.5)
#
# png(file="/user/home/uy23281/scratch/rmd.results/corrplot_mshr_m4.png")
# corrplot(x, method='color', col.lim=c(0,1), type='upper', addCoef.col = "black", tl.col="black", tl.srt=45, title = 'Pairwise Sharing by Magnitude', mar = c(4,0,4,0))
# dev.off()
```


```{r,echo=FALSE}
head(get_significant_results(m.c))
```
To extract the estimates of the mixture proportions for different types of covariance matrix we can use **get_estimated_pi()** function and plot the estimates. 

```{r,echo=FALSE}
# Plots
print(get_estimated_pi(m.c))
barplot(get_estimated_pi(m.c),las = 2)

```
There is another function in mashr package, **get_pairwise_sharing()** that compute the proportion of significant signals shared by magnitude in the estimated effect sizes, for each pair of conditions. For each pair of conditions, first identify the effects that are significant in at least one of the two conditions. Then compute what fraction of these have an estimated (posterior mean) effect size within a factor factor of one another.

```{r,echo=FALSE}
corrplot(x, method='color', col.lim=c(0,1), type='upper', addCoef.col = "black", tl.col="black", tl.srt=45, title = 'Pairwise Sharing by Magnitude', mar = c(4,0,4,0))
```
